{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKOTlwcmxmej"
      },
      "source": [
        "# GPT-2 Fine-Tuning Tutorial with PyTorch & Huggingface in Colab\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKGBoVwuhM4H"
      },
      "source": [
        "This is a simplified script for fine-tuning GPT2 using Hugging Face's [Transformers library](https://huggingface.co/transformers/) and PyTorch.\n",
        "\n",
        "You should understand the basics of PyTorch and how a training loop works before getting started. [This official PyTorch tutorial](https://pytorch.org/tutorials/beginner/nn_tutorial.html) serves as an excellent introduction. Familiarity with the workings of GPT2 might be useful but isn't required. The code has been written for clarity and not re-use. I'd advise refactoring it for actual projects. I've liberally taken bits from [Chris McCormick's BERT fine-tuning tutorial](https://mccormickml.com/2019/07/22/BERT-fine-tuning/), [Ian Porter's GPT2 tutorial](https://snappishproductions.com/blog/2020/03/01/chapter-9.5-text-generation-with-gpt-2-and-only-pytorch.html.html) and the [Hugging Face Language model fine-tuning script](https://huggingface.co/transformers/v2.0.0/examples.html#language-model-fine-tuning) so full credit to them. Chris' code has pretty much provided the basis for this script - you should definitely check out his [blog](https://mccormickml.com/tutorials/).\n",
        "\n",
        "I should mention what the script doesn't cover:\n",
        "\n",
        "- Using the [nlp](https://huggingface.co/nlp/) library to load in the dataset and setting up the training workflow, which looks to streamline things rather nicely.\n",
        "- [Accumulated gradients](https://medium.com/huggingface/training-larger-batches-practical-tips-on-1-gpu-multi-gpu-distributed-setups-ec88c3e51255) - this gives larger effective batch sizes than Colab allows (GPT2 is a large model, and anything more than a batch size of 2 would be enough to get a CUDA out of memory error on Colab).\n",
        "- [Freezing layers](https://github.com/huggingface/transformers/issues/1431). This is the process of only changing the parameters in selected layers, made famous by the [ULMFit](https://arxiv.org/abs/1801.06146) process.\n",
        "- [Using 'past'](https://huggingface.co/transformers/quickstart.html#using-the-past) when generating text. This takes in the previous state when generating successive items of text. I didn't need it.\n",
        "- [Tensor packing](https://snappishproductions.com/blog/2020/03/01/chapter-9.5-text-generation-with-gpt-2-and-only-pytorch.html.html). This is a neat way of fitting in as much training data in each batch. \n",
        "- [Hyperparameter search](https://discuss.huggingface.co/t/using-hyperparameter-search-in-trainer/785/10). I settled quickly on values that seemed to produce decent values, without checking if they were optimal."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xf3Qw77SZGbS"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCCeyhuDHdOu",
        "outputId": "ecdfd48a-c8c5-43f8-d27b-07ba93c868e8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split, RandomSampler, SequentialSampler\n",
        "torch.manual_seed(42)\n",
        "\n",
        "from transformers import GPT2LMHeadModel,  GPT2Tokenizer, GPT2Config, GPT2LMHeadModel\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "satxtOn9CzgR",
        "outputId": "d26ad102-7c5a-4897-d844-028fa636692c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU 0: NVIDIA GeForce RTX 2080 Ti (UUID: GPU-3121ccbe-3d4b-3ba9-ce07-af624d3ca998)\n",
            "GPU 1: NVIDIA GeForce RTX 2080 Ti (UUID: GPU-9807473d-3644-9912-cc3d-05880ab4ef36)\n",
            "GPU 2: NVIDIA GeForce RTX 2080 Ti (UUID: GPU-94db0646-211f-c99a-ea07-d9859dc5a87b)\n",
            "GPU 3: NVIDIA GeForce RTX 2080 Ti (UUID: GPU-f5267ef4-d399-295f-b58e-91baa2652af9)\n",
            "GPU 4: NVIDIA GeForce RTX 2080 Ti (UUID: GPU-66accfdf-33c3-3764-dae1-4c8efaefa2f0)\n",
            "GPU 5: NVIDIA GeForce RTX 2080 Ti (UUID: GPU-486ef60c-26e5-41c4-7810-29630050ae19)\n",
            "GPU 6: NVIDIA GeForce RTX 2080 Ti (UUID: GPU-602bcadd-6da5-b336-2e0c-ffabb97367a4)\n",
            "GPU 7: NVIDIA GeForce RTX 2080 Ti (UUID: GPU-02afb69a-63bc-02a2-a8d8-df52eb0a5226)\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi -L"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfdCML6Parvv"
      },
      "source": [
        "# Create Training Set\n",
        "\n",
        "The data used to finetune the language model is a set of around 1000 DJ biographies, with the aim of generating them in the same general format and style.\n",
        "\n",
        "This data isn't public so if you want to use this script, you'll have to source your own training set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv('preprocessed_the-office-lines_scripts.csv', sep=';')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_U3m6wr3Ahzt",
        "outputId": "ddde3e3e-d741-40dc-be21-1b3e2dac1fb2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0       [ Michael ] : All right Jim . Your quarterlies...\n",
              "1       [ Michael ] : [ phone ] Yes , I would like spe...\n",
              "2       [ Michael ] : I , uh , I Dunder Mifflin 12 yea...\n",
              "3       [ Michael ] : People say I best boss . They go...\n",
              "4       [ Dwight ] : [ singing ] Shall I play ? Pa rum...\n",
              "                              ...                        \n",
              "8844    [ Creed ] : It seems arbitrary . I applied job...\n",
              "8845    [ Meredith ] : I feel lucky I got chance share...\n",
              "8846    [ Phyllis ] : I happy filmed I remember everyo...\n",
              "8847    [ Jim ] : I sold paper company 12 years . My j...\n",
              "8848    [ Pam ] : I thought weird picked us make docum...\n",
              "Name: line_text, Length: 8849, dtype: object"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.dropna(inplace=True) #remove NA values\n",
        "bios = df.line_text.copy() #just use the main bio text in this example\n",
        "bios"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQ1oK0kXaV5p"
      },
      "source": [
        "We need to get an idea of how long our training documents are.\n",
        "\n",
        "I'm not going to use the same tokenizer as the GPT2 one, which is a [byte pair encoding tokenizer](https://blog.floydhub.com/tokenization-nlp/). Instead, I'm using a simple one just to get a rough understanding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "cKsH2sU0OCQA",
        "outputId": "76b422fc-30c8-4135-aa8c-6aec6f0d7840"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_3472960/3284538386.py:12: UserWarning: \n",
            "\n",
            "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
            "\n",
            "Please adapt your code to use either `displot` (a figure-level function with\n",
            "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "\n",
            "For a guide to updating your code to use the new functions, please see\n",
            "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
            "\n",
            "  sns.distplot(doc_lengths)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Axes: ylabel='Density'>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "doc_lengths = []\n",
        "\n",
        "for bio in bios:\n",
        "\n",
        "    # get rough token count distribution\n",
        "    tokens = nltk.word_tokenize(bio)\n",
        "\n",
        "    doc_lengths.append(len(tokens))\n",
        "\n",
        "doc_lengths = np.array(doc_lengths)\n",
        "\n",
        "sns.distplot(doc_lengths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6P6bTItJEIj",
        "outputId": "fc6ba587-2c7d-4ef0-997b-b1f4271117ae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.00045202847779410104"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# the max token length   \n",
        "len(doc_lengths[doc_lengths > 768])/len(doc_lengths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63t_69HjlwAj",
        "outputId": "1d3d907a-f8cc-4c7d-b200-2e63fdad096f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "92.38806644818624"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.average(doc_lengths)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMml12FJGjPW"
      },
      "source": [
        "# GPT2 Tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANJhbBwdxN-b"
      },
      "source": [
        "Although the defaults take care of this,I thought I'd show that you can specify some of the special tokens. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z474sSC6oe7A",
        "outputId": "a812cad5-cc12-480b-a28d-5b08bde704b4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "# Load the GPT tokenizer.\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2', bos_token='<|startoftext|>', eos_token='<|endoftext|>', pad_token='<|pad|>') #gpt2-medium\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sh0XKuDvnryn",
        "outputId": "d0906c06-c46d-4a16-e6a1-1a43fd345cca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The max model length is 1024 for this model, although the actual embedding size for GPT small is 768\n",
            "The beginning of sequence token <|startoftext|> token has the id 50257\n",
            "The end of sequence token <|endoftext|> has the id 50256\n",
            "The padding token <|pad|> has the id 50258\n"
          ]
        }
      ],
      "source": [
        "print(\"The max model length is {} for this model, although the actual embedding size for GPT small is 768\".format(tokenizer.model_max_length))\n",
        "print(\"The beginning of sequence token {} token has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.bos_token_id), tokenizer.bos_token_id))\n",
        "print(\"The end of sequence token {} has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.eos_token_id), tokenizer.eos_token_id))\n",
        "print(\"The padding token {} has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.pad_token_id), tokenizer.pad_token_id))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ex5O1eV-Pfct"
      },
      "source": [
        "# PyTorch Datasets & Dataloaders\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lgZoOYkxZfx"
      },
      "source": [
        "GPT2 is a large model. Increasing the batch size above 2 has lead to out of memory problems. This can be mitigated by accumulating the gradients but that is out of scope here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "scqrzmqhV__z"
      },
      "outputs": [],
      "source": [
        "batch_size = 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqGMee7Isfpx"
      },
      "source": [
        "I'm using the standard PyTorch approach of loading data in using a [dataset class](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html).\n",
        "\n",
        "I'm passing in the tokenizer as an argument but normally I would  instantiate it within the class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "U_XJVIetKN-h"
      },
      "outputs": [],
      "source": [
        "class GPT2Dataset(Dataset):\n",
        "\n",
        "  def __init__(self, txt_list, tokenizer, gpt2_type=\"gpt2\", max_length=512):\n",
        "\n",
        "    self.tokenizer = tokenizer\n",
        "    self.input_ids = []\n",
        "    self.attn_masks = []\n",
        "\n",
        "    for txt in txt_list:\n",
        "\n",
        "      encodings_dict = tokenizer('<|startoftext|>'+ txt + '<|endoftext|>', truncation=True, max_length=max_length, padding=\"max_length\")\n",
        "\n",
        "      self.input_ids.append(torch.tensor(encodings_dict['input_ids']))\n",
        "      self.attn_masks.append(torch.tensor(encodings_dict['attention_mask']))\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.input_ids)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.input_ids[idx], self.attn_masks[idx] "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89Z7aYUgpWrd"
      },
      "source": [
        "To understand how I've used the tokenizer, it's worth reading [the docs](https://huggingface.co/transformers/main_classes/tokenizer.html). I've wrapped each bio in the bos and eos tokens.\n",
        "\n",
        "Every tensor passed to the model should be the same length.\n",
        "\n",
        "If the bio is shorter than 768 tokens, it will be padded to a length of 768 using the padding token. In addition, an attention mask will be returned that needs to be passed to the model to tell it to ignore the padding tokens. \n",
        "\n",
        "If the bio is longer than 768 tokens, it will be truncated without the eos_token. This isn't a problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xza_O1_rD7yh",
        "outputId": "b6aa0809-9d45-49fd-b92d-41594ab0127d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7,964 training samples\n",
            "  885 validation samples\n"
          ]
        }
      ],
      "source": [
        "dataset = GPT2Dataset(bios, tokenizer, max_length=512)\n",
        "\n",
        "# Split into training and validation sets\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "x0WeP5PREUuy"
      },
      "outputs": [],
      "source": [
        "# Create the DataLoaders for our training and validation datasets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6TKgyUzPIQc"
      },
      "source": [
        "# Finetune GPT2 Language Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "gFsCTp_mporB"
      },
      "outputs": [
        {
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 10.76 GiB total capacity; 148.00 MiB already allocated; 4.81 MiB free; 148.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_3472960/3298263384.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Tell pytorch to run this model on the GPU.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Set the seed value all over the place to make this reproducible.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    747\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m         \"\"\"\n\u001b[0;32m--> 749\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mipu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    662\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    747\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m         \"\"\"\n\u001b[0;32m--> 749\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mipu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 10.76 GiB total capacity; 148.00 MiB already allocated; 4.81 MiB free; 148.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ],
      "source": [
        "# I'm not really doing anything with the config buheret\n",
        "configuration = GPT2Config.from_pretrained('gpt2', output_hidden_states=False)\n",
        "\n",
        "# instantiate the model\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2\", config=configuration)\n",
        "\n",
        "# this step is necessary because I've added some tokens (bos_token, etc) to the embeddings\n",
        "# otherwise the tokenizer and model tensors won't match up\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "device = torch.device(\"cuda\")\n",
        "model.cuda()\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "pBEVY2PYSTXJ"
      },
      "outputs": [],
      "source": [
        "# some parameters I cooked up that work reasonably well\n",
        "\n",
        "epochs = 5\n",
        "learning_rate = 5e-4\n",
        "warmup_steps = 1e2\n",
        "epsilon = 1e-8\n",
        "\n",
        "# this produces sample output every 100 steps\n",
        "sample_every = 500"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLs72DuMODJO",
        "outputId": "c83b38d5-55af-42bb-98a2-8a2fd6b5e5e9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = learning_rate,\n",
        "                  eps = epsilon\n",
        "                )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(50257, 50256, 50258)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.bos_token_id, tokenizer.eos_token_id, tokenizer.pad_token_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "-p0upAhhRiIx"
      },
      "outputs": [],
      "source": [
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "# This changes the learning rate as the training loop progresses\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = warmup_steps, \n",
        "                                            num_training_steps = total_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "gpt6tR83keZD"
      },
      "outputs": [],
      "source": [
        "def format_time(elapsed):\n",
        "    return str(datetime.timedelta(seconds=int(round((elapsed)))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCPohrZ-CTWu",
        "outputId": "dec21857-0661-4977-90df-29e5ddc0df40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 5 ========\n",
            "Training...\n",
            "  Batch   500  of  1,593. Loss: 0.42338404059410095.   Elapsed: 0:02:26.\n",
            "0: [ Dwight ] : Whoa.\n",
            "  Batch 1,000  of  1,593. Loss: 0.4674864411354065.   Elapsed: 0:04:53.\n",
            "0: [ Dwight ] : Hey guys, everyone. [ Karen ] : What? [ Dwight ] : [ nervous ] [ Karen ] : Good, I good news. Yeah, okay. [ Dwight ] : Uh, I. [ Karen ] : I really disappointed. What I meant? [ Dwight ] : Oh, I think. [ Karen ] : Well, I think, I think, I feel like. [ Dwight ] : And, um,... um. That I thinking?\n",
            "  Batch 1,500  of  1,593. Loss: 0.6733189225196838.   Elapsed: 0:07:20.\n",
            "0: [ Michael ] : What time day? [ Ryan ] : I little bit late getting information. [ Michael ] : Good. It uh, know? Good, enough, let us go go, take care, okay? [ Ryan ] : Thank... [ Michael ] : [ laughs ] And... yeah, let us go, go. [ Ryan ] : Yeah, I really sorry. You know, I... I... I sorry I going. Okay. Oh, good.\n",
            "\n",
            "  Average training loss: 0.79\n",
            "  Training epoch took: 0:07:48\n",
            "Saving model...\n",
            "Running Validation...\n",
            "  Validation Loss: 0.63\n",
            "  Validation took: 0:00:17\n",
            "\n",
            "======== Epoch 2 / 5 ========\n",
            "Training...\n",
            "  Batch   500  of  1,593. Loss: 0.6478253602981567.   Elapsed: 0:02:26.\n",
            "0: [ Jim ] : [ Michael Jim Dwight, Michael Jim Dwight's new apartment, Dwight Dwight's wife Carol ] I think might nice, really big deal. [ Jim ] : No, going. You look cute little, come. [ Dwight ] : Thank, Jim. That good decision. Good. [ Jim ] : You told Pam would's wedding. But? [ Dwight ] : [ Pam ] Uh, yeah, I know, I mean Pam's big wedding. So good. [ Jim ] : You going love.\n",
            "  Batch 1,000  of  1,593. Loss: 0.5743259787559509.   Elapsed: 0:04:54.\n",
            "0: [ Ryan ] : We going set. So I think going make little play I guess. [ Kevin ] : Alright, guys going make move. [ Ryan ] : If I put little piece pepperoni mouth, I going kill... [ Kevin ] : No,. We going kill. [ Ryan ] : If let us move, [ Oscar ] : Come! [ Ryan ] : We move!\n",
            "  Batch 1,500  of  1,593. Loss: 0.7348850965499878.   Elapsed: 0:07:21.\n",
            "0: [ Andy ] : [ entering building ] Hello. My name Andy Bernard. [ Dwight ] : Hello. Dwight Schrute. [ Andy ] : Dwight Schrute. [ Dwight ] : [ approaching building ] Hello. [ Michael ] : Hi. I work. [ Andy ] : Oh, Michael. [ Michael ] : So... [ Andy ] : [ exhales ] [ Michael ] : Hello? [ Andy ] : [ whispers ] Hi... [ Michael ] : Hi... [ Andy ] : [ whispers ] Michael? [ Michael ] : [ whispers ] You [ whispers ] I... [ exhales ]\n",
            "\n",
            "  Average training loss: 0.61\n",
            "  Training epoch took: 0:07:49\n",
            "Saving model...\n",
            "Running Validation...\n",
            "  Validation Loss: 0.62\n",
            "  Validation took: 0:00:17\n",
            "\n",
            "======== Epoch 3 / 5 ========\n",
            "Training...\n",
            "  Batch   500  of  1,593. Loss: 0.21396328508853912.   Elapsed: 0:02:26.\n",
            "0: [ Pam ] : You said think could keep secrets, I never tell anyone. [ Dwight ] : [ whispering ] Do even know I would believe. [ Pam ] : But... I would know something. [ Dwight ] : Okay, Pam, I see way. Let us go. Just go. No,. We go.\n",
            "  Batch 1,000  of  1,593. Loss: 0.595951497554779.   Elapsed: 0:04:53.\n",
            "0: [ Michael ] : [ sitting Meredith desk talking Michael's phone ] Yeah, uh,? I see. [ Andy ] : Yeah. You guys, going like hang new phone. [ Andy ] : Oh, yeah, yeah. Oh God, really? [ Andy ] : Yeah. You ready? [ Michael ] : Yeah, I already got phone. Right? I got one. I already bought one. All right, I give one. That right. No. No. Here go. Here go. [ Andy ] : [ slams phone desk ] [ Michael ] : [ sitting Meredith desk ] We take look. [ Meredith ] : [ sighs ] Look, I go. This good.\n",
            "  Batch 1,500  of  1,593. Loss: 0.35677066445350647.   Elapsed: 0:07:21.\n",
            "0: [ Oscar ] : [ Pam's office ] What? [ Pam ] : Nothing. [ Oscar ] : The office really, really going like party planning committee. I mean, could... [ Pam ] : I know, Oscar. [ Oscar ] : Okay, good. See? [ Angela ] : [ laughs ] This whole thing made fun.\n",
            "\n",
            "  Average training loss: 0.55\n",
            "  Training epoch took: 0:07:49\n",
            "Saving model...\n",
            "Running Validation...\n",
            "  Validation Loss: 0.63\n",
            "  Validation took: 0:00:17\n",
            "\n",
            "======== Epoch 4 / 5 ========\n",
            "Training...\n",
            "  Batch   500  of  1,593. Loss: 0.39632683992385864.   Elapsed: 0:02:26.\n",
            "0: [ Andy ] : [ office ] Are ready? [ Jim ] : Mm-hmm. [ Andy ] : Oh, yeah. Listen, look, uh, want see office. [ Jim ] : Uh, yeah, I see. [ Andy ] : I could go work. [ Jim ] : Well, um, going really cool. Just,, uh,, I, might, I got go home. [ Andy ] : Well, actually, I got. Thanks. [ Jim ] : All right. So, get back... [ Andy ] : Okay. [ Jim ] : Great. Thanks. [ Andy ] : Thank much. [ Jim ] : Okay.\n",
            "  Batch 1,000  of  1,593. Loss: 0.3230334520339966.   Elapsed: 0:04:54.\n",
            "0: [ Jim ] : It looks like something interesting.\n",
            "  Batch 1,500  of  1,593. Loss: 0.5044325590133667.   Elapsed: 0:07:21.\n",
            "0: [ Robert ] : I know Bob, right? He works warehouse. And I love hanging around. So tell, huh? What I say? [ Jim ] : [ sighs ] What? [ Robert ] : Because I need really good sales rep. I need someone else I need sell I need someone else. [ Jim ] : [ looks Creed ] Well, let us get back, huh? I need sell... OK. OK. [ Robert ] : And.... [ Jim ] : You right? There time. So wait, right? [ Robert ] : [ sighs ] That real name. And real name.\n",
            "\n",
            "  Average training loss: 0.49\n",
            "  Training epoch took: 0:07:49\n",
            "Saving model...\n",
            "Running Validation...\n",
            "  Validation Loss: 0.66\n",
            "  Validation took: 0:00:17\n",
            "\n",
            "======== Epoch 5 / 5 ========\n",
            "Training...\n",
            "  Batch   500  of  1,593. Loss: 0.787115752696991.   Elapsed: 0:02:27.\n",
            "0: [ Angela ] : [ Oscar ] You know? I sorry. I going go talk. [ Oscar ] : [ laughs ] I know, I could go. [ Angela ] : [ grabs box back, opens back ] You. [ Oscar ] : [ scoffs ] [ Angela ] : Come. [ Oscar ] : [ smacks Angela hand arm ] Oh, God. No,. You.\n",
            "  Batch 1,000  of  1,593. Loss: 0.6201085448265076.   Elapsed: 0:04:54.\n",
            "0: [ Dwight ] : There nothing horizon except time. And time passed, time came, time came. And one day, God smiled upon us. And I smiled upon Him. All I see staring, staring away. I going laugh heartily. I going laugh heartily. I going laugh heartily, one day, I going laugh heartily.\n",
            "  Batch 1,500  of  1,593. Loss: 0.5700874328613281.   Elapsed: 0:07:21.\n",
            "0: [ Stanley ] : So, uh, going? [ Stanley ] : No. I need make decision. [ Oscar ] : Well... [ Stanley ] : Because know, I really want know, uh, I going to-oh. [ laughs ] That, know. [ Oscar ] : What joke? [ Stanley ] : Umm.... I... [ Oscar ] : It, I take, I going let go. [ Stanley ] : Are serious? [ Oscar ] : Are serious? [ Stanley ] : What, man? [ Phyllis ] : I thought coming. You leave. [ Stanley ] : Fine. [ Phyllis ] : Bye. [ Stanley ] : Bye. [ Jim ] : Hey, Ryan. [ Ryan ] : Hey. [ Jim ] : Good. [ Ryan ] : [ Jim takes picture Stanley's car ] Oh, hey!\n",
            "\n",
            "  Average training loss: 0.43\n",
            "  Training epoch took: 0:07:50\n",
            "Saving model...\n",
            "Running Validation...\n",
            "  Validation Loss: 0.69\n",
            "  Validation took: 0:00:17\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:40:33 (h:mm:ss)\n"
          ]
        }
      ],
      "source": [
        "total_t0 = time.time()\n",
        "\n",
        "training_stats = []\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "for epoch_i in range(0, epochs):\n",
        "\n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    total_train_loss = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_labels = batch[0].to(device)\n",
        "        b_masks = batch[1].to(device)\n",
        "\n",
        "        model.zero_grad()        \n",
        "\n",
        "        outputs = model(  b_input_ids,\n",
        "                          labels=b_labels, \n",
        "                          attention_mask = b_masks,\n",
        "                          token_type_ids=None\n",
        "                        )\n",
        "\n",
        "        loss = outputs[0]  \n",
        "\n",
        "        batch_loss = loss.item()\n",
        "        total_train_loss += batch_loss\n",
        "\n",
        "        # Get sample every x batches.\n",
        "        if step % sample_every == 0 and not step == 0:\n",
        "\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print('  Batch {:>5,}  of  {:>5,}. Loss: {:>5,}.   Elapsed: {:}.'.format(step, len(train_dataloader), batch_loss, elapsed))\n",
        "\n",
        "            model.eval()\n",
        "\n",
        "            sample_outputs = model.generate(\n",
        "                                    bos_token_id=tokenizer.bos_token_id,\n",
        "                                    pad_token_id=tokenizer.pad_token_id,\n",
        "                                    eos_token_id=tokenizer.eos_token_id,\n",
        "                                    do_sample=True,   \n",
        "                                    top_k=50, \n",
        "                                    max_length = 200,\n",
        "                                    top_p=0.95, \n",
        "                                    num_return_sequences=1\n",
        "                                )\n",
        "            for i, sample_output in enumerate(sample_outputs):\n",
        "                  print(\"{}: {}\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))\n",
        "            \n",
        "            model.train()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)       \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epoch took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "\n",
        "    print(\"Saving model...\")\n",
        "\n",
        "    torch.save(model.state_dict(), f'model_epoch_{epoch_i}.pth')\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_labels = batch[0].to(device)\n",
        "        b_masks = batch[1].to(device)\n",
        "        \n",
        "        with torch.no_grad():        \n",
        "\n",
        "            outputs  = model(b_input_ids, \n",
        "#                            token_type_ids=None, \n",
        "                             attention_mask = b_masks,\n",
        "                            labels=b_labels)\n",
        "          \n",
        "            loss = outputs[0]  \n",
        "            \n",
        "        batch_loss = loss.item()\n",
        "        total_eval_loss += batch_loss        \n",
        "\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    validation_time = format_time(time.time() - t0)    \n",
        "\n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQTvJ1vRP7u4"
      },
      "source": [
        "Let's view the summary of the training process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "6O_NbXFGMukX",
        "outputId": "8cd1b38b-f419-4694-a154-01298a9ae53d"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'training_stats' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_3472960/141254203.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Create a DataFrame from our training statistics.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdf_stats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_stats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Use the 'epoch' as the row index.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'training_stats' is not defined"
          ]
        }
      ],
      "source": [
        "# Display floats with two decimal places.\n",
        "#pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# A hack to force the column headers to wrap.\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "68xreA9JAmG5",
        "outputId": "28452100-a93a-47e7-aee4-62abd6fa5c2d"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfjYoa6WmkN6"
      },
      "source": [
        "# Display Model Info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PIiVlDYCtSq",
        "outputId": "4a25ab95-7804-4d59-89e9-c503df68a885"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The GPT-2 model has 148 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "transformer.wte.weight                                  (50259, 768)\n",
            "transformer.wpe.weight                                   (1024, 768)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "transformer.h.0.ln_1.weight                                   (768,)\n",
            "transformer.h.0.ln_1.bias                                     (768,)\n",
            "transformer.h.0.attn.c_attn.weight                       (768, 2304)\n",
            "transformer.h.0.attn.c_attn.bias                             (2304,)\n",
            "transformer.h.0.attn.c_proj.weight                        (768, 768)\n",
            "transformer.h.0.attn.c_proj.bias                              (768,)\n",
            "transformer.h.0.ln_2.weight                                   (768,)\n",
            "transformer.h.0.ln_2.bias                                     (768,)\n",
            "transformer.h.0.mlp.c_fc.weight                          (768, 3072)\n",
            "transformer.h.0.mlp.c_fc.bias                                (3072,)\n",
            "transformer.h.0.mlp.c_proj.weight                        (3072, 768)\n",
            "transformer.h.0.mlp.c_proj.bias                               (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "transformer.ln_f.weight                                       (768,)\n",
            "transformer.ln_f.bias                                         (768,)\n"
          ]
        }
      ],
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The GPT-2 model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:2]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[2:14]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-2:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2079Qyn8Mt8"
      },
      "source": [
        "# Saving & Loading Fine-Tuned Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "6ulTWaOr8QNY",
        "outputId": "88b0b93e-3024-42ab-d9a9-38324f69d704"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving model to ./model_save/\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "('./model_save/tokenizer_config.json',\n",
              " './model_save/special_tokens_map.json',\n",
              " './model_save/vocab.json',\n",
              " './model_save/merges.txt',\n",
              " './model_save/added_tokens.json')"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
        "\n",
        "output_dir = './model_save/'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()`\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "# Good practice: save your training arguments together with the trained model\n",
        "#torch.save(args, os.path.join(output_dir, 'training_args.bin'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVBbURBRix8j",
        "outputId": "4193d81b-4307-41f3-aa18-cb96c4c4d6b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/bin/bash: whereami: command not found\n"
          ]
        }
      ],
      "source": [
        "!whereami"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqMzI3VTCZo5",
        "outputId": "f2221dcf-c620-4f0d-ee02-53a2daca3172"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total 499888K\n",
            "-rw-r--r-- 1 root root      1K Mar  9 17:59 added_tokens.json\n",
            "-rw-r--r-- 1 root root      1K Mar  9 17:59 config.json\n",
            "-rw-r--r-- 1 root root      1K Mar  9 17:59 generation_config.json\n",
            "-rw-r--r-- 1 root root    446K Mar  9 17:59 merges.txt\n",
            "-rw-r--r-- 1 root root 498442K Mar  9 17:59 pytorch_model.bin\n",
            "-rw-r--r-- 1 root root      1K Mar  9 17:59 special_tokens_map.json\n",
            "-rw-r--r-- 1 root root      1K Mar  9 17:59 tokenizer_config.json\n",
            "-rw-r--r-- 1 root root    976K Mar  9 17:59 vocab.json\n"
          ]
        }
      ],
      "source": [
        "!ls -l --block-size=K ./model_save/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WUFUIQ8Cu8D",
        "outputId": "b7cde7b1-e7b5-48d2-d946-8af7af5e0a1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-rw-r--r-- 1 root root 487M Mar  9 17:59 ./model_save/pytorch_model.bin\n"
          ]
        }
      ],
      "source": [
        "!ls -l --block-size=M ./model_save/pytorch_model.bin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9zhc87ljk35"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), 'model.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 148.00 MiB (GPU 0; 10.76 GiB total capacity; 148.00 MiB already allocated; 4.81 MiB free; 148.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_3472960/716092282.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# load already trained models from file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_epoch_12.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    787\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mUNSAFE_MESSAGE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mweights_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1129\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnpicklerWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1131\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_loaded_sparse_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1099\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m             \u001b[0mnbytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumel\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1101\u001b[0;31m             \u001b[0mload_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_maybe_decode_ascii\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1081\u001b[0m         \u001b[0;31m# stop wrapping with TypedStorage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1082\u001b[0m         loaded_storages[key] = torch.storage.TypedStorage(\n\u001b[0;32m-> 1083\u001b[0;31m             \u001b[0mwrap_storage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrestore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1084\u001b[0m             dtype=dtype)\n\u001b[1;32m   1085\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdefault_restore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_package_registry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    185\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUntypedStorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_mps_deserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36m_cuda\u001b[0;34m(self, device, non_blocking, **kwargs)\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             untyped_storage = torch.UntypedStorage(\n\u001b[0m\u001b[1;32m     81\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             )\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 148.00 MiB (GPU 0; 10.76 GiB total capacity; 148.00 MiB already allocated; 4.81 MiB free; 148.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ],
      "source": [
        "# load already trained models from file\n",
        "\n",
        "model.load_state_dict(torch.load('model_epoch_12.pth'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLf6rbRglYhQ"
      },
      "source": [
        "# Generate Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4XhewaV93-_",
        "outputId": "3d2db3b6-5af9-4606-a633-8ee702b2b628"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\schla\\git\\NLP-The-Office\\notebooks\\THE_OFFICE_scene_generation_GPT_2_Fine_Tuning.ipynb Cell 48\u001b[0m in \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/schla/git/NLP-The-Office/notebooks/THE_OFFICE_scene_generation_GPT_2_Fine_Tuning.ipynb#X65sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39meval()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/schla/git/NLP-The-Office/notebooks/THE_OFFICE_scene_generation_GPT_2_Fine_Tuning.ipynb#X65sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m prompt \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mJim:\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/schla/git/NLP-The-Office/notebooks/THE_OFFICE_scene_generation_GPT_2_Fine_Tuning.ipynb#X65sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m generated \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(tokenizer\u001b[39m.\u001b[39mencode(prompt))\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "\n",
        "prompt = \"Jim:\"\n",
        "\n",
        "generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
        "generated = generated.to(device)\n",
        "\n",
        "print(generated)\n",
        "\n",
        "sample_outputs = model.generate(\n",
        "                                generated, \n",
        "                                #bos_token_id=random.randint(1,30000),\n",
        "                                do_sample=True,   \n",
        "                                eos_token_id=tokenizer.eos_token_id,\n",
        "                                bos_token_id=tokenizer.bos_token_id,\n",
        "                                top_k=50, \n",
        "                                max_length = 300,\n",
        "                                top_p=0.999, \n",
        "                                num_return_sequences=5\n",
        "                                )\n",
        "\n",
        "for i, sample_output in enumerate(sample_outputs):\n",
        "  print(\"{}: {}\\n\\n\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4LrX5H-0nAU"
      },
      "source": [
        "These aren't bad at all!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'<|startoftext|> [ Dwight ] : I got shotgun, I got. I got. I got. [ Clark ] : Whoa. What?<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>'"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.decode(sample_outputs[0])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
